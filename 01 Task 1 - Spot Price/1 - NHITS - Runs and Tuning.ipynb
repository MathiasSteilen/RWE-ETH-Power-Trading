{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The blackcellmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext blackcellmagic\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import plotnine as pn\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import neuralforecast\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, NBEATSx, NHITS\n",
    "from neuralforecast.auto import AutoNBEATS, AutoNHITS\n",
    "from neuralforecast.losses.pytorch import MQLoss, DistributionLoss, MSE, MAE\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset\n",
    "from neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.pipeline import FeatureUnion, make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    FunctionTransformer,\n",
    ")\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import config_context\n",
    "import optuna\n",
    "import os\n",
    "import holidays\n",
    "\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Focus on CH spot price first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>auction_price_ch_de</th>\n",
       "      <th>auction_price_de_ch</th>\n",
       "      <th>dst</th>\n",
       "      <th>day_ahead_price_at</th>\n",
       "      <th>day_ahead_price_ch</th>\n",
       "      <th>day_ahead_price_de</th>\n",
       "      <th>day_ahead_price_fr</th>\n",
       "      <th>day_ahead_price_it</th>\n",
       "      <th>actual_load_at</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_offshore_actual_aggregated_it</th>\n",
       "      <th>wind_offshore_forecast_de</th>\n",
       "      <th>wind_onshore_actual_aggregated_at</th>\n",
       "      <th>wind_onshore_actual_aggregated_de</th>\n",
       "      <th>wind_onshore_actual_aggregated_fr</th>\n",
       "      <th>wind_onshore_actual_aggregated_it</th>\n",
       "      <th>wind_onshore_ch</th>\n",
       "      <th>wind_onshore_forecast_at</th>\n",
       "      <th>wind_onshore_forecast_de</th>\n",
       "      <th>wind_onshore_forecast_fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00+00:00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.09</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.25</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3390.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>35415.50</td>\n",
       "      <td>13933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00+00:00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.50</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3395.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>35146.75</td>\n",
       "      <td>13583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00+00:00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.45</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.71</td>\n",
       "      <td>-5.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3410.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>34449.00</td>\n",
       "      <td>13230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00+00:00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9.08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.71</td>\n",
       "      <td>-4.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3431.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>897.0</td>\n",
       "      <td>33905.25</td>\n",
       "      <td>12877.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00+00:00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.15</td>\n",
       "      <td>-5.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3454.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>697.0</td>\n",
       "      <td>33362.75</td>\n",
       "      <td>12311.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  auction_price_ch_de  auction_price_de_ch  dst  \\\n",
       "0 2023-01-01 00:00:00+00:00                 0.01                 6.09    1   \n",
       "1 2023-01-01 01:00:00+00:00                 0.01                 5.50    1   \n",
       "2 2023-01-01 02:00:00+00:00                 0.01                 6.45    1   \n",
       "3 2023-01-01 03:00:00+00:00                 0.01                 9.08    1   \n",
       "4 2023-01-01 04:00:00+00:00                 0.01                13.33    1   \n",
       "\n",
       "   day_ahead_price_at  day_ahead_price_ch  day_ahead_price_de  \\\n",
       "0                 NaN               -7.25               -1.07   \n",
       "1                 NaN               -3.99               -1.47   \n",
       "2                 NaN               -7.71               -5.08   \n",
       "3                 NaN               -9.71               -4.49   \n",
       "4                 NaN              -15.15               -5.40   \n",
       "\n",
       "   day_ahead_price_fr  day_ahead_price_it  actual_load_at  ...  \\\n",
       "0                 NaN                 NaN             NaN  ...   \n",
       "1                 NaN                 NaN             NaN  ...   \n",
       "2                 NaN                 NaN             NaN  ...   \n",
       "3                 NaN                 NaN             NaN  ...   \n",
       "4                 NaN                 NaN             NaN  ...   \n",
       "\n",
       "   wind_offshore_actual_aggregated_it  wind_offshore_forecast_de  \\\n",
       "0                                 NaN                    3390.25   \n",
       "1                                 NaN                    3395.50   \n",
       "2                                 NaN                    3410.25   \n",
       "3                                 NaN                    3431.25   \n",
       "4                                 NaN                    3454.25   \n",
       "\n",
       "   wind_onshore_actual_aggregated_at  wind_onshore_actual_aggregated_de  \\\n",
       "0                                NaN                                NaN   \n",
       "1                                NaN                                NaN   \n",
       "2                                NaN                                NaN   \n",
       "3                                NaN                                NaN   \n",
       "4                                NaN                                NaN   \n",
       "\n",
       "   wind_onshore_actual_aggregated_fr  wind_onshore_actual_aggregated_it  \\\n",
       "0                                NaN                                NaN   \n",
       "1                                NaN                                NaN   \n",
       "2                                NaN                                NaN   \n",
       "3                                NaN                                NaN   \n",
       "4                                NaN                                NaN   \n",
       "\n",
       "   wind_onshore_ch  wind_onshore_forecast_at  wind_onshore_forecast_de  \\\n",
       "0              NaN                    1174.0                  35415.50   \n",
       "1              NaN                    1194.0                  35146.75   \n",
       "2              NaN                    1085.0                  34449.00   \n",
       "3              NaN                     897.0                  33905.25   \n",
       "4              NaN                     697.0                  33362.75   \n",
       "\n",
       "   wind_onshore_forecast_fr  \n",
       "0                   13933.0  \n",
       "1                   13583.0  \n",
       "2                   13230.0  \n",
       "3                   12877.0  \n",
       "4                   12311.0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../00 Data Retrieval and Cleaning/0_df_final_ml_predictive.csv\",\n",
    "    parse_dates=[\"date\"],\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to lag the other three target variables by 24 hours, haven't done that yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df\n",
    "    .assign(\n",
    "        day_ahead_price_de=lambda x: x[\"day_ahead_price_de\"].shift(24),\n",
    "        auction_price_de_ch=lambda x: x[\"auction_price_de_ch\"].shift(24),\n",
    "        auction_price_ch_de=lambda x: x[\"auction_price_ch_de\"].shift(24),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Feature Generation\n",
    "\n",
    "- There might be a benefit of encoding cyclical calendar information\n",
    "- Additionally: Holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include a trend column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(trend=lambda x: x.index, unique_id=\"spot_ch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the country (Switzerland)\n",
    "country = \"CH\"\n",
    "\n",
    "regional_holidays = holidays.CH(\n",
    "    years=df.date.dt.year.unique().tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday_name</th>\n",
       "      <th>holiday_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neujahrestag</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Auffahrt</td>\n",
       "      <td>2023-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nationalfeiertag</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Weihnachten</td>\n",
       "      <td>2023-12-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neujahrestag</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       holiday_name holiday_date\n",
       "4      Neujahrestag   2023-01-01\n",
       "5          Auffahrt   2023-05-18\n",
       "6  Nationalfeiertag   2023-08-01\n",
       "7       Weihnachten   2023-12-25\n",
       "0      Neujahrestag   2024-01-01"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holiday_df = pd.DataFrame(\n",
    "    {\n",
    "        \"holiday_name\": list(regional_holidays.values()),\n",
    "        \"holiday_date\": list(regional_holidays.keys()),\n",
    "    }\n",
    ")\n",
    "\n",
    "holiday_df.sort_values(\"holiday_date\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "holiday_name\n",
       "Auffahrt            2\n",
       "Nationalfeiertag    2\n",
       "Neujahrestag        2\n",
       "Weihnachten         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holiday_df.value_counts(\"holiday_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.assign(\n",
    "        hour=lambda x: x.date.dt.hour + 1,\n",
    "        month=lambda x: x.date.dt.month,\n",
    "        quarter=lambda x: x.date.dt.quarter,\n",
    "        wday=lambda x: x.date.dt.day_of_week + 1,\n",
    "        weekend=lambda x: np.where(\n",
    "            x.date.dt.day_name().isin([\"Sunday\", \"Saturday\"]), 1, 0\n",
    "        ),\n",
    "        work_hour=lambda x: np.where(\n",
    "            x[\"hour\"].isin(np.arange(17, 24).tolist() + np.arange(1, 5).tolist()), 0, 1\n",
    "        ),\n",
    "        week_hour=lambda x: x.date.dt.dayofweek * 24 + (x.date.dt.hour + 1),\n",
    "        year=lambda x: x.date.dt.year,\n",
    "        hour_counter=lambda x: np.arange(0, x.shape[0]),\n",
    "    )\n",
    "    .assign(day=lambda x: x.date.dt.date)\n",
    "    .merge(holiday_df, how=\"left\", left_on=\"day\", right_on=\"holiday_date\")\n",
    "    .drop([\"holiday_date\", \"day\"], axis=1)\n",
    "    .assign(\n",
    "        holiday_name=lambda x: np.where(\n",
    "            x[\"holiday_name\"].isna(), \"none\", x[\"holiday_name\"]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "holiday_name\n",
       "none                9381\n",
       "Neujahrestag          48\n",
       "Auffahrt              24\n",
       "Nationalfeiertag      24\n",
       "Weihnachten           24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts(\"holiday_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other:\n",
    "- `date`: drop, can't feed into net\n",
    "\n",
    "Numerical:\n",
    "- everything but `holiday_name`\n",
    "\n",
    "Categorical\n",
    "- `holiday_name`: one-hot encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cyclical Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- avoid issue with exploding feature space when one-hot encoding hundreds of levels in categorical vars\n",
    "- puts end of cycle closer to beginning (End of Year is not that different from BOY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
    "\n",
    "\n",
    "def cos_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hour in day\n",
    "df[\"hour_sin\"] = sin_transformer(24).fit_transform(df[\"hour\"].astype(float))\n",
    "df[\"hour_cos\"] = cos_transformer(24).fit_transform(df[\"hour\"].astype(float))\n",
    "\n",
    "# hour in week\n",
    "df[\"week_hour_sin\"] = sin_transformer(168).fit_transform(df[\"week_hour\"].astype(float))\n",
    "df[\"week_hour_cos\"] = cos_transformer(168).fit_transform(df[\"week_hour\"].astype(float))\n",
    "\n",
    "# month\n",
    "df[\"month_sin\"] = sin_transformer(12).fit_transform(df[\"month\"].astype(float))\n",
    "df[\"month_cos\"] = cos_transformer(12).fit_transform(df[\"month\"].astype(float))\n",
    "\n",
    "# quarter\n",
    "df[\"quarter_sin\"] = sin_transformer(4).fit_transform(df[\"quarter\"].astype(float))\n",
    "df[\"quarter_cos\"] = cos_transformer(4).fit_transform(df[\"quarter\"].astype(float))\n",
    "\n",
    "# weekday\n",
    "df[\"wday_sin\"] = sin_transformer(7).fit_transform(df[\"wday\"].astype(float))\n",
    "df[\"wday_cos\"] = cos_transformer(7).fit_transform(df[\"wday\"].astype(float))\n",
    "\n",
    "df = df.drop([\"hour\", \"month\", \"quarter\", \"wday\", \"week_hour\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `sklearn` Pipeline for Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_cols = [\"trend\", \"unique_id\"]\n",
    "drop_cols = [\"date\", \"day_ahead_price_ch\"]\n",
    "\n",
    "pipeline_cols = [\n",
    "    col\n",
    "    for col in df.drop(drop_cols, axis=1).columns\n",
    "    if col not in manual_cols\n",
    "]\n",
    "\n",
    "num_cols = (\n",
    "    df.drop(drop_cols, axis=1)\n",
    "    .filter(pipeline_cols)\n",
    "    .select_dtypes(include=np.number)\n",
    "    .columns\n",
    ")\n",
    "cat_cols = (\n",
    "    df.drop(drop_cols, axis=1)\n",
    "    .filter(pipeline_cols)\n",
    "    .select_dtypes(exclude=np.number)\n",
    "    .columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['auction_price_ch_de',\n",
       " 'auction_price_de_ch',\n",
       " 'dst',\n",
       " 'day_ahead_price_at',\n",
       " 'day_ahead_price_de',\n",
       " 'day_ahead_price_fr',\n",
       " 'day_ahead_price_it',\n",
       " 'actual_load_at',\n",
       " 'actual_load_ch',\n",
       " 'actual_load_de',\n",
       " 'actual_load_fr',\n",
       " 'actual_load_it',\n",
       " 'allocated_capacity_ch_de',\n",
       " 'allocated_capacity_de_ch',\n",
       " 'biomass_actual_aggregated_at',\n",
       " 'biomass_actual_aggregated_de',\n",
       " 'biomass_actual_aggregated_fr',\n",
       " 'biomass_actual_aggregated_it',\n",
       " 'capacity_forecast_at_ch',\n",
       " 'capacity_forecast_ch_at',\n",
       " 'capacity_forecast_ch_de_lu',\n",
       " 'capacity_forecast_ch_fr',\n",
       " 'capacity_forecast_ch_it',\n",
       " 'capacity_forecast_de_lu_ch',\n",
       " 'capacity_forecast_fr_ch',\n",
       " 'capacity_forecast_it_ch',\n",
       " 'crossborder_actual_flow_at_ch',\n",
       " 'crossborder_actual_flow_ch_at',\n",
       " 'crossborder_actual_flow_ch_de_lu',\n",
       " 'crossborder_actual_flow_ch_fr',\n",
       " 'crossborder_actual_flow_ch_it',\n",
       " 'crossborder_actual_flow_de_lu_ch',\n",
       " 'crossborder_actual_flow_fr_ch',\n",
       " 'crossborder_actual_flow_it_ch',\n",
       " 'fossil_brown_coal_lignite_actual_aggregated_de',\n",
       " 'fossil_coal_derived_gas_actual_aggregated_it',\n",
       " 'fossil_gas_actual_aggregated_at',\n",
       " 'fossil_gas_actual_aggregated_de',\n",
       " 'fossil_gas_actual_aggregated_fr',\n",
       " 'fossil_gas_actual_aggregated_it',\n",
       " 'fossil_hard_coal_actual_aggregated_de',\n",
       " 'fossil_hard_coal_actual_aggregated_fr',\n",
       " 'fossil_hard_coal_actual_aggregated_it',\n",
       " 'fossil_oil_actual_aggregated_de',\n",
       " 'fossil_oil_actual_aggregated_fr',\n",
       " 'fossil_oil_actual_aggregated_it',\n",
       " 'geothermal_actual_aggregated_de',\n",
       " 'geothermal_actual_aggregated_it',\n",
       " 'hydro_pumped_storage_actual_aggregated_at',\n",
       " 'hydro_pumped_storage_actual_aggregated_de',\n",
       " 'hydro_pumped_storage_actual_aggregated_fr',\n",
       " 'hydro_pumped_storage_actual_aggregated_it',\n",
       " 'hydro_pumped_storage_actual_consumption_at',\n",
       " 'hydro_pumped_storage_actual_consumption_de',\n",
       " 'hydro_pumped_storage_actual_consumption_fr',\n",
       " 'hydro_pumped_storage_actual_consumption_it',\n",
       " 'hydro_pumped_storage_ch',\n",
       " 'hydro_reservoir_storage_at',\n",
       " 'hydro_reservoir_storage_ch',\n",
       " 'hydro_reservoir_storage_fr',\n",
       " 'hydro_reservoir_storage_it',\n",
       " 'hydro_run_of_river_and_poundage_actual_aggregated_at',\n",
       " 'hydro_run_of_river_and_poundage_actual_aggregated_de',\n",
       " 'hydro_run_of_river_and_poundage_actual_aggregated_fr',\n",
       " 'hydro_run_of_river_and_poundage_actual_aggregated_it',\n",
       " 'hydro_run_of_river_and_poundage_ch',\n",
       " 'hydro_water_reservoir_actual_aggregated_at',\n",
       " 'hydro_water_reservoir_actual_aggregated_de',\n",
       " 'hydro_water_reservoir_actual_aggregated_fr',\n",
       " 'hydro_water_reservoir_actual_aggregated_it',\n",
       " 'hydro_water_reservoir_ch',\n",
       " 'nuclear_actual_aggregated_de',\n",
       " 'nuclear_actual_aggregated_fr',\n",
       " 'nuclear_ch',\n",
       " 'other_actual_aggregated_de',\n",
       " 'other_actual_aggregated_it',\n",
       " 'other_renewable_actual_aggregated_de',\n",
       " 'solar_actual_aggregated_at',\n",
       " 'solar_actual_aggregated_de',\n",
       " 'solar_actual_aggregated_fr',\n",
       " 'solar_actual_aggregated_it',\n",
       " 'solar_ch',\n",
       " 'solar_forecast_at',\n",
       " 'solar_forecast_ch',\n",
       " 'solar_forecast_de',\n",
       " 'solar_forecast_fr',\n",
       " 'solar_forecast_it',\n",
       " 'waste_actual_aggregated_de',\n",
       " 'waste_actual_aggregated_fr',\n",
       " 'waste_actual_aggregated_it',\n",
       " 'wind_offshore_actual_aggregated_de',\n",
       " 'wind_offshore_actual_aggregated_fr',\n",
       " 'wind_offshore_actual_aggregated_it',\n",
       " 'wind_offshore_forecast_de',\n",
       " 'wind_onshore_actual_aggregated_at',\n",
       " 'wind_onshore_actual_aggregated_de',\n",
       " 'wind_onshore_actual_aggregated_fr',\n",
       " 'wind_onshore_actual_aggregated_it',\n",
       " 'wind_onshore_ch',\n",
       " 'wind_onshore_forecast_at',\n",
       " 'wind_onshore_forecast_de',\n",
       " 'wind_onshore_forecast_fr',\n",
       " 'weekend',\n",
       " 'work_hour',\n",
       " 'year',\n",
       " 'hour_counter',\n",
       " 'holiday_name',\n",
       " 'hour_sin',\n",
       " 'hour_cos',\n",
       " 'week_hour_sin',\n",
       " 'week_hour_cos',\n",
       " 'month_sin',\n",
       " 'month_cos',\n",
       " 'quarter_sin',\n",
       " 'quarter_cos',\n",
       " 'wday_sin',\n",
       " 'wday_cos']"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['auction_price_ch_de', 'auction_price_de_ch', 'dst',\n",
       "       'day_ahead_price_at', 'day_ahead_price_de', 'day_ahead_price_fr',\n",
       "       'day_ahead_price_it', 'actual_load_at', 'actual_load_ch',\n",
       "       'actual_load_de',\n",
       "       ...\n",
       "       'hour_sin', 'hour_cos', 'week_hour_sin', 'week_hour_cos', 'month_sin',\n",
       "       'month_cos', 'quarter_sin', 'quarter_cos', 'wday_sin', 'wday_cos'],\n",
       "      dtype='object', length=116)"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['holiday_name'], dtype='object')"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer()),\n",
    "        #    (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\n",
    "            \"encoder\",\n",
    "            OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Making column transformer where all transformers in the pipelines are included\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_transformer, num_cols),\n",
    "        (\"categorical\", categorical_transformer, cat_cols),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end = pd.Timestamp(\"2023-09-01\").tz_localize(\"UTC\")\n",
    "val_end = pd.Timestamp(\"2024-01-01\").tz_localize(\"UTC\")\n",
    "\n",
    "# Create splits\n",
    "df_train = df.query(\"date < @val_end\")\n",
    "# df_val = df.query(\"date < @val_end\").query(\"ds >= @train_end\").head(500)\n",
    "df_test = df.query(\"date >= @val_end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"date\", \"day_ahead_price_ch\"])\n",
    "y_train = df_train[\"day_ahead_price_ch\"]\n",
    "\n",
    "X_test = df_test.drop(columns=[\"date\", \"day_ahead_price_ch\"])\n",
    "y_test = df_test[\"day_ahead_price_ch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_preprocessor = preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = pd.DataFrame(\n",
    "    fitted_preprocessor.transform(X_train),\n",
    "    columns=fitted_preprocessor.get_feature_names_out(),\n",
    ")\n",
    "X_test_preprocessed = pd.DataFrame(\n",
    "    fitted_preprocessor.transform(X_test),\n",
    "    columns=fitted_preprocessor.get_feature_names_out(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace prefixes in column names\n",
    "new_cols = X_train_preprocessed.columns.str.replace('numeric__', '').str.replace('categorical__', '').str.replace('remainder__', '')\n",
    "\n",
    "# Assign new column names to the DataFrame\n",
    "X_train_preprocessed.columns = new_cols\n",
    "X_test_preprocessed.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_price_ch_de</th>\n",
       "      <th>auction_price_de_ch</th>\n",
       "      <th>dst</th>\n",
       "      <th>day_ahead_price_at</th>\n",
       "      <th>day_ahead_price_de</th>\n",
       "      <th>day_ahead_price_fr</th>\n",
       "      <th>day_ahead_price_it</th>\n",
       "      <th>actual_load_at</th>\n",
       "      <th>actual_load_ch</th>\n",
       "      <th>actual_load_de</th>\n",
       "      <th>...</th>\n",
       "      <th>quarter_cos</th>\n",
       "      <th>wday_sin</th>\n",
       "      <th>wday_cos</th>\n",
       "      <th>holiday_name_Auffahrt</th>\n",
       "      <th>holiday_name_Nationalfeiertag</th>\n",
       "      <th>holiday_name_Neujahrestag</th>\n",
       "      <th>holiday_name_Weihnachten</th>\n",
       "      <th>holiday_name_none</th>\n",
       "      <th>trend</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.337356</td>\n",
       "      <td>14.528225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.39752</td>\n",
       "      <td>95.427349</td>\n",
       "      <td>97.109492</td>\n",
       "      <td>127.814714</td>\n",
       "      <td>6637.036266</td>\n",
       "      <td>6970.689146</td>\n",
       "      <td>52843.424376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>spot_ch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.337356</td>\n",
       "      <td>14.528225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.39752</td>\n",
       "      <td>95.427349</td>\n",
       "      <td>97.109492</td>\n",
       "      <td>127.814714</td>\n",
       "      <td>6637.036266</td>\n",
       "      <td>6970.689146</td>\n",
       "      <td>52843.424376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>spot_ch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.337356</td>\n",
       "      <td>14.528225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.39752</td>\n",
       "      <td>95.427349</td>\n",
       "      <td>97.109492</td>\n",
       "      <td>127.814714</td>\n",
       "      <td>6637.036266</td>\n",
       "      <td>6970.689146</td>\n",
       "      <td>52843.424376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>spot_ch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.337356</td>\n",
       "      <td>14.528225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.39752</td>\n",
       "      <td>95.427349</td>\n",
       "      <td>97.109492</td>\n",
       "      <td>127.814714</td>\n",
       "      <td>6637.036266</td>\n",
       "      <td>6970.689146</td>\n",
       "      <td>52843.424376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>spot_ch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.337356</td>\n",
       "      <td>14.528225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.39752</td>\n",
       "      <td>95.427349</td>\n",
       "      <td>97.109492</td>\n",
       "      <td>127.814714</td>\n",
       "      <td>6637.036266</td>\n",
       "      <td>6970.689146</td>\n",
       "      <td>52843.424376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>spot_ch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  auction_price_ch_de auction_price_de_ch  dst day_ahead_price_at  \\\n",
       "0            1.337356           14.528225  1.0          102.39752   \n",
       "1            1.337356           14.528225  1.0          102.39752   \n",
       "2            1.337356           14.528225  1.0          102.39752   \n",
       "3            1.337356           14.528225  1.0          102.39752   \n",
       "4            1.337356           14.528225  1.0          102.39752   \n",
       "\n",
       "  day_ahead_price_de day_ahead_price_fr day_ahead_price_it actual_load_at  \\\n",
       "0          95.427349          97.109492         127.814714    6637.036266   \n",
       "1          95.427349          97.109492         127.814714    6637.036266   \n",
       "2          95.427349          97.109492         127.814714    6637.036266   \n",
       "3          95.427349          97.109492         127.814714    6637.036266   \n",
       "4          95.427349          97.109492         127.814714    6637.036266   \n",
       "\n",
       "  actual_load_ch actual_load_de  ... quarter_cos wday_sin wday_cos  \\\n",
       "0    6970.689146   52843.424376  ...         0.0     -0.0      1.0   \n",
       "1    6970.689146   52843.424376  ...         0.0     -0.0      1.0   \n",
       "2    6970.689146   52843.424376  ...         0.0     -0.0      1.0   \n",
       "3    6970.689146   52843.424376  ...         0.0     -0.0      1.0   \n",
       "4    6970.689146   52843.424376  ...         0.0     -0.0      1.0   \n",
       "\n",
       "  holiday_name_Auffahrt holiday_name_Nationalfeiertag  \\\n",
       "0                   0.0                           0.0   \n",
       "1                   0.0                           0.0   \n",
       "2                   0.0                           0.0   \n",
       "3                   0.0                           0.0   \n",
       "4                   0.0                           0.0   \n",
       "\n",
       "  holiday_name_Neujahrestag holiday_name_Weihnachten holiday_name_none trend  \\\n",
       "0                       1.0                      0.0               0.0     0   \n",
       "1                       1.0                      0.0               0.0     1   \n",
       "2                       1.0                      0.0               0.0     2   \n",
       "3                       1.0                      0.0               0.0     3   \n",
       "4                       1.0                      0.0               0.0     4   \n",
       "\n",
       "  unique_id  \n",
       "0   spot_ch  \n",
       "1   spot_ch  \n",
       "2   spot_ch  \n",
       "3   spot_ch  \n",
       "4   spot_ch  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat(\n",
    "    [\n",
    "        df_train[\"date\"].reset_index(drop=True),\n",
    "        y_train.reset_index(drop=True),\n",
    "        X_train_preprocessed.reset_index(drop=True),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "df_test = pd.concat(\n",
    "    [\n",
    "        df_test[\"date\"].reset_index(drop=True),\n",
    "        y_test.reset_index(drop=True),\n",
    "        X_test_preprocessed.reset_index(drop=True),\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an initial model for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>auction_price_ch_de</th>\n",
       "      <th>auction_price_de_ch</th>\n",
       "      <th>dst</th>\n",
       "      <th>day_ahead_price_at</th>\n",
       "      <th>day_ahead_price_de</th>\n",
       "      <th>day_ahead_price_fr</th>\n",
       "      <th>day_ahead_price_it</th>\n",
       "      <th>actual_load_at</th>\n",
       "      <th>...</th>\n",
       "      <th>quarter_cos</th>\n",
       "      <th>wday_sin</th>\n",
       "      <th>wday_cos</th>\n",
       "      <th>holiday_name_Auffahrt</th>\n",
       "      <th>holiday_name_Nationalfeiertag</th>\n",
       "      <th>holiday_name_Neujahrestag</th>\n",
       "      <th>holiday_name_Weihnachten</th>\n",
       "      <th>holiday_name_none</th>\n",
       "      <th>trend</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00+00:00</td>\n",
       "      <td>-7.25</td>\n",
       "      <td>1.337356</td>\n",
       "      <td>14.528225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.39752</td>\n",
       "      <td>95.427349</td>\n",
       "      <td>97.109492</td>\n",
       "      <td>127.814714</td>\n",
       "      <td>6637.036266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>spot_ch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00+00:00</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>1.337356</td>\n",
       "      <td>14.528225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.39752</td>\n",
       "      <td>95.427349</td>\n",
       "      <td>97.109492</td>\n",
       "      <td>127.814714</td>\n",
       "      <td>6637.036266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>spot_ch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00+00:00</td>\n",
       "      <td>-7.71</td>\n",
       "      <td>1.337356</td>\n",
       "      <td>14.528225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.39752</td>\n",
       "      <td>95.427349</td>\n",
       "      <td>97.109492</td>\n",
       "      <td>127.814714</td>\n",
       "      <td>6637.036266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>spot_ch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00+00:00</td>\n",
       "      <td>-9.71</td>\n",
       "      <td>1.337356</td>\n",
       "      <td>14.528225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.39752</td>\n",
       "      <td>95.427349</td>\n",
       "      <td>97.109492</td>\n",
       "      <td>127.814714</td>\n",
       "      <td>6637.036266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>spot_ch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00+00:00</td>\n",
       "      <td>-15.15</td>\n",
       "      <td>1.337356</td>\n",
       "      <td>14.528225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.39752</td>\n",
       "      <td>95.427349</td>\n",
       "      <td>97.109492</td>\n",
       "      <td>127.814714</td>\n",
       "      <td>6637.036266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>spot_ch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ds      y auction_price_ch_de auction_price_de_ch  \\\n",
       "0 2023-01-01 00:00:00+00:00  -7.25            1.337356           14.528225   \n",
       "1 2023-01-01 01:00:00+00:00  -3.99            1.337356           14.528225   \n",
       "2 2023-01-01 02:00:00+00:00  -7.71            1.337356           14.528225   \n",
       "3 2023-01-01 03:00:00+00:00  -9.71            1.337356           14.528225   \n",
       "4 2023-01-01 04:00:00+00:00 -15.15            1.337356           14.528225   \n",
       "\n",
       "   dst day_ahead_price_at day_ahead_price_de day_ahead_price_fr  \\\n",
       "0  1.0          102.39752          95.427349          97.109492   \n",
       "1  1.0          102.39752          95.427349          97.109492   \n",
       "2  1.0          102.39752          95.427349          97.109492   \n",
       "3  1.0          102.39752          95.427349          97.109492   \n",
       "4  1.0          102.39752          95.427349          97.109492   \n",
       "\n",
       "  day_ahead_price_it actual_load_at  ... quarter_cos wday_sin wday_cos  \\\n",
       "0         127.814714    6637.036266  ...         0.0     -0.0      1.0   \n",
       "1         127.814714    6637.036266  ...         0.0     -0.0      1.0   \n",
       "2         127.814714    6637.036266  ...         0.0     -0.0      1.0   \n",
       "3         127.814714    6637.036266  ...         0.0     -0.0      1.0   \n",
       "4         127.814714    6637.036266  ...         0.0     -0.0      1.0   \n",
       "\n",
       "  holiday_name_Auffahrt holiday_name_Nationalfeiertag  \\\n",
       "0                   0.0                           0.0   \n",
       "1                   0.0                           0.0   \n",
       "2                   0.0                           0.0   \n",
       "3                   0.0                           0.0   \n",
       "4                   0.0                           0.0   \n",
       "\n",
       "  holiday_name_Neujahrestag holiday_name_Weihnachten holiday_name_none trend  \\\n",
       "0                       1.0                      0.0               0.0     0   \n",
       "1                       1.0                      0.0               0.0     1   \n",
       "2                       1.0                      0.0               0.0     2   \n",
       "3                       1.0                      0.0               0.0     3   \n",
       "4                       1.0                      0.0               0.0     4   \n",
       "\n",
       "  unique_id  \n",
       "0   spot_ch  \n",
       "1   spot_ch  \n",
       "2   spot_ch  \n",
       "3   spot_ch  \n",
       "4   spot_ch  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.rename(columns={\"day_ahead_price_ch\": \"y\", \"date\": \"ds\"})\n",
    "df_test = df_test.rename(columns={\"day_ahead_price_ch\": \"y\", \"date\": \"ds\"})\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    }
   ],
   "source": [
    "model = NHITS(\n",
    "    h=38,\n",
    "    input_size=168,\n",
    "    loss=MSE(),\n",
    "    max_steps=500,\n",
    "    val_check_steps=5,\n",
    "    early_stop_patience_steps=3,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MSE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.8 M \n",
      "-----------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.320    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2ec83caf4c40bba0117c2b0b0946f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16a6477abb342c69be01d28429ab492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceed6b0f39b3492abe2d77c1bcf34bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd84794c317405fab9e3344b286880b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6617933e7b4552a96c61849aace50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1e010a69f24a6eadfb5b2d34e5e90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b94a94277ee44d1a0803065208c3587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea30a0e54f441a39034f4f83e95d90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990a37c8254b4036bb9052320b79402f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58dc5f2f6eb3403f84a150d01dddfa7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a21e5ad5c94b38bd9e458d7849adec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3731c6215e1643899f977e0e0830d28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c21204f2a1e4037a7cdbaeef83d364a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3587892ef94adf94e65d01b6b0c512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc20117701e4495a2a925834c5daa08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "nf = NeuralForecast(models=[model], freq=\"h\")\n",
    "nf.fit(df=df_train, val_size=int(df_train.shape[0]*0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\utilsforecast\\processing.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5224e2246e6b480093fd4ef0c011a30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\miniconda3\\envs\\statslab\\lib\\site-packages\\neuralforecast\\core.py:196: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>NHITS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-01-31 23:00:00+00:00</td>\n",
       "      <td>67.274689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 00:00:00+00:00</td>\n",
       "      <td>65.179718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 01:00:00+00:00</td>\n",
       "      <td>64.587646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 02:00:00+00:00</td>\n",
       "      <td>66.609329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 03:00:00+00:00</td>\n",
       "      <td>69.711349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 04:00:00+00:00</td>\n",
       "      <td>78.695633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 05:00:00+00:00</td>\n",
       "      <td>84.606789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 06:00:00+00:00</td>\n",
       "      <td>88.782806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 07:00:00+00:00</td>\n",
       "      <td>89.023102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 08:00:00+00:00</td>\n",
       "      <td>85.628059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 09:00:00+00:00</td>\n",
       "      <td>80.628815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 10:00:00+00:00</td>\n",
       "      <td>78.570923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 11:00:00+00:00</td>\n",
       "      <td>77.098824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 12:00:00+00:00</td>\n",
       "      <td>75.740013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 13:00:00+00:00</td>\n",
       "      <td>75.950409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 14:00:00+00:00</td>\n",
       "      <td>77.404671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 15:00:00+00:00</td>\n",
       "      <td>81.597878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 16:00:00+00:00</td>\n",
       "      <td>86.103859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 17:00:00+00:00</td>\n",
       "      <td>89.252167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 18:00:00+00:00</td>\n",
       "      <td>89.594147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 19:00:00+00:00</td>\n",
       "      <td>84.752045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 20:00:00+00:00</td>\n",
       "      <td>78.963905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 21:00:00+00:00</td>\n",
       "      <td>72.862129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 22:00:00+00:00</td>\n",
       "      <td>68.600098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-01 23:00:00+00:00</td>\n",
       "      <td>64.128220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-02 00:00:00+00:00</td>\n",
       "      <td>62.459419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-02 01:00:00+00:00</td>\n",
       "      <td>61.171902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-02 02:00:00+00:00</td>\n",
       "      <td>61.865211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-02 03:00:00+00:00</td>\n",
       "      <td>66.665329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-02 04:00:00+00:00</td>\n",
       "      <td>72.698547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-02 05:00:00+00:00</td>\n",
       "      <td>79.441597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-02 06:00:00+00:00</td>\n",
       "      <td>82.672768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-02 07:00:00+00:00</td>\n",
       "      <td>82.302612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-02 08:00:00+00:00</td>\n",
       "      <td>79.027946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-02 09:00:00+00:00</td>\n",
       "      <td>74.337212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-02 10:00:00+00:00</td>\n",
       "      <td>72.448265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-02 11:00:00+00:00</td>\n",
       "      <td>70.676132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spot_ch</th>\n",
       "      <td>2024-02-02 12:00:00+00:00</td>\n",
       "      <td>70.159248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ds      NHITS\n",
       "unique_id                                     \n",
       "spot_ch   2024-01-31 23:00:00+00:00  67.274689\n",
       "spot_ch   2024-02-01 00:00:00+00:00  65.179718\n",
       "spot_ch   2024-02-01 01:00:00+00:00  64.587646\n",
       "spot_ch   2024-02-01 02:00:00+00:00  66.609329\n",
       "spot_ch   2024-02-01 03:00:00+00:00  69.711349\n",
       "spot_ch   2024-02-01 04:00:00+00:00  78.695633\n",
       "spot_ch   2024-02-01 05:00:00+00:00  84.606789\n",
       "spot_ch   2024-02-01 06:00:00+00:00  88.782806\n",
       "spot_ch   2024-02-01 07:00:00+00:00  89.023102\n",
       "spot_ch   2024-02-01 08:00:00+00:00  85.628059\n",
       "spot_ch   2024-02-01 09:00:00+00:00  80.628815\n",
       "spot_ch   2024-02-01 10:00:00+00:00  78.570923\n",
       "spot_ch   2024-02-01 11:00:00+00:00  77.098824\n",
       "spot_ch   2024-02-01 12:00:00+00:00  75.740013\n",
       "spot_ch   2024-02-01 13:00:00+00:00  75.950409\n",
       "spot_ch   2024-02-01 14:00:00+00:00  77.404671\n",
       "spot_ch   2024-02-01 15:00:00+00:00  81.597878\n",
       "spot_ch   2024-02-01 16:00:00+00:00  86.103859\n",
       "spot_ch   2024-02-01 17:00:00+00:00  89.252167\n",
       "spot_ch   2024-02-01 18:00:00+00:00  89.594147\n",
       "spot_ch   2024-02-01 19:00:00+00:00  84.752045\n",
       "spot_ch   2024-02-01 20:00:00+00:00  78.963905\n",
       "spot_ch   2024-02-01 21:00:00+00:00  72.862129\n",
       "spot_ch   2024-02-01 22:00:00+00:00  68.600098\n",
       "spot_ch   2024-02-01 23:00:00+00:00  64.128220\n",
       "spot_ch   2024-02-02 00:00:00+00:00  62.459419\n",
       "spot_ch   2024-02-02 01:00:00+00:00  61.171902\n",
       "spot_ch   2024-02-02 02:00:00+00:00  61.865211\n",
       "spot_ch   2024-02-02 03:00:00+00:00  66.665329\n",
       "spot_ch   2024-02-02 04:00:00+00:00  72.698547\n",
       "spot_ch   2024-02-02 05:00:00+00:00  79.441597\n",
       "spot_ch   2024-02-02 06:00:00+00:00  82.672768\n",
       "spot_ch   2024-02-02 07:00:00+00:00  82.302612\n",
       "spot_ch   2024-02-02 08:00:00+00:00  79.027946\n",
       "spot_ch   2024-02-02 09:00:00+00:00  74.337212\n",
       "spot_ch   2024-02-02 10:00:00+00:00  72.448265\n",
       "spot_ch   2024-02-02 11:00:00+00:00  70.676132\n",
       "spot_ch   2024-02-02 12:00:00+00:00  70.159248"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf.predict(df_test, step_size=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statslab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
