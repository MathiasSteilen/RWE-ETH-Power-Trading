---
title: "Data cleaning"
author: "Federico Deotto"
date: "2024-03-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(ggsci)
library(scales)
library(tidymodels)

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

# Default theme for charts
theme_set(
  theme_bw() +
    theme(  
      plot.title = element_text(face = "bold", size = 14),
      plot.subtitle = element_text(
        face = "italic", size = 10, colour = "grey50"
      )
    )
)

```

## The Goal

Select variables based on availability (NA) and variance, ensuring conversion to the appropriate type (e.g., converting integers into numeric data).

```{r}
# Read data - both direction JAO
data_ch_de = read_csv("../00_Data Retrieval and Cleaning/0_df_final_ch-de_UTC.csv")
data_de_ch = read_csv("../00_Data Retrieval and Cleaning/0_df_final_de-ch_UTC.csv")
data_ch_de <- data_ch_de %>%
  rename(auction_price_ch_de = auction_price)

#Initialize df that contain ALL variables
df <- data_ch_de %>% 
  mutate(auction_price_de_ch = data_de_ch$auction_price) %>% 
  select(-dst) %>% 
  arrange(date)

rm(data_ch_de, data_de_ch)
```


Remove the most recent rows that contains NA:
```{r}
split_date = ymd_hm("2024-01-31 23:00")
df <- df %>% 
  filter(date < split_date)
```



Variables to remove:

```{r}
# Find columns with zero or near-zero variance
remove_cols <- apply(df, 2, function(x) var(x, na.rm = T) < 1e-10)
remove_cols <- ifelse(is.na(remove_cols), F, remove_cols)
colnames(df)[remove_cols] #name variable no variance

df <- df[, !remove_cols]
```
### Missing value

How many columns have more than x% missing data?

```{r}
tibble(
  percentage = seq(0.01, 0.99, by = 0.01),
  cols = map_dbl(percentage, function(pct){
    df |> 
      select(
        colMeans(is.na(df)) |> 
          enframe() |>
          filter(value > pct) |> 
          pull(name) 
      ) |> 
      ncol()
  })
) |> 
  ggplot(aes(percentage, cols)) +
  geom_line() +
  geom_point() +
  labs(title = "Number of columns with more than x% missing values",
       y = "# of cols", x = "Minimum Missing Percentage") +
  scale_x_continuous(breaks = seq(0, 1, 0.1), labels = percent_format())
```

Agree with M. to limit ourselves with the 30% (/10%)

```{r}
df = df |> 
  select(
    colMeans(is.na(df)) |> 
      enframe() |>
      filter(value < 0.3) |> 
      pull(name) 
  )
```

Visualise the missingness in those columns that still have missing values:

```{r}
df |> 
  select(
    colMeans(is.na(df)) |> 
      enframe() |>
      filter(value > 0) |> 
      pull(name)
  ) |> 
  naniar::vis_miss(warn_large_data = F)
```

Impute the missing values with Random Forest:

```{r}
set.seed(1234)
df_imputed = missRanger::missRanger(
  df,
  num.trees = 3,
  sample.fraction = 0.1,
  verbose = 1
)
```

Save the dataset in a file so we can use it in the future with the same imputation.

```{r}
write.csv(df_imputed, "data_cleaned_UTC.csv", row.names = FALSE)
```