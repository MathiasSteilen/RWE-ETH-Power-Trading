---
title: "Data cleaning"
author: "Federico Deotto"
date: "2024-03-12"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(ggsci)
library(scales)
# library(tidymodels)

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

# Default theme for charts
theme_set(
  theme_bw() +
    theme(  
      plot.title = element_text(face = "bold", size = 14),
      plot.subtitle = element_text(
        face = "italic", size = 10, colour = "grey50"
      )
    )
)

```

## The Goal

Select variables based on availability (NA) and variance, ensuring conversion to the appropriate type (e.g., converting integers into numeric data).

```{r}
# Read data - both direction JAO
data_ch_de = read_csv("../00 Data Retrieval and Cleaning/0_df_final_ch-de_UTC.csv")
data_de_ch = read_csv("../00 Data Retrieval and Cleaning/0_df_final_de-ch_UTC.csv")

data_ch_de <- data_ch_de %>%
  rename(auction_price_ch_de = auction_price,
         allocatedCapacity_ch_de = allocatedCapacity, ATC_ch_de = ATC)

#Initialize df that contain ALL variables
df <- data_ch_de %>% 
  mutate(auction_price_de_ch = data_de_ch$auction_price, 
         allocatedCapacity_de_ch= data_de_ch$allocatedCapacity, 
         ATC_de_ch= data_de_ch$ATC) %>% 
  arrange(date)

rm(data_ch_de, data_de_ch)
```


Remove the most recent rows that contains NA:

```{r}
split_date = ymd_hm("2024-01-31 23:00")
df <- df %>% 
  filter(date < split_date)
```


Find and remove zero variance variables:
```{r}
remove_cols = df |> 
  select(-c(date)) |> 
  pivot_longer(everything()) |> 
  group_by(name) |> 
  summarise(var = var(value, na.rm = T)) |> 
  ungroup() |> 
  filter(var < 1e-10) |> 
  pull(name)

df = df |> 
  select(!all_of(remove_cols))
```

### Missing value

How many columns have more than x% missing data?
```{r}
tibble(
  percentage = seq(0.01, 0.99, by = 0.01),
  cols = map_dbl(percentage, function(pct){
    df |> 
      select(
        colMeans(is.na(df)) |> 
          enframe() |>
          filter(value > pct) |> 
          pull(name) 
      ) |> 
      ncol()
  })
) |> 
  ggplot(aes(percentage, cols)) +
  geom_line() +
  geom_point() +
  labs(title = "Number of columns with more than x% missing values",
       y = "# of cols", x = "Minimum Missing Percentage") +
  scale_x_continuous(breaks = seq(0, 1, 0.1), 
                     labels = percent_format())
```

We are limiting ourselves to >60% of missing data columns being discarded. Discard them:

```{r}
# Discard the columns with too many missing values (threshold 70%)
df = df |> 
  select(-(df |> 
             is.na() |> 
             colMeans() |> 
             enframe() |> 
             filter(value > 0.6) |> 
             pull(name)))
```

These two columns are not missing at random, they're pumped storage values, fill the NA values with zero:

```{r}
df |> 
  select(hydro_pumped_storage_actual_aggregated_fr,
         hydro_pumped_storage_actual_consumption_fr) |> 
  is.na() |> 
  colMeans()

df |> 
  select(hydro_pumped_storage_actual_aggregated_fr,
         hydro_pumped_storage_actual_consumption_fr) |> 
  mutate(tmp = xor(is.na(hydro_pumped_storage_actual_aggregated_fr),
                   is.na(hydro_pumped_storage_actual_consumption_fr))) |> 
  summarise(xor_missing = mean(tmp))

df |> 
  slice(5200:5300) |> 
  select(date, 
         hydro_pumped_storage_actual_aggregated_fr,
         hydro_pumped_storage_actual_consumption_fr) |> 
  pivot_longer(-date) |> 
  ggplot(aes(date, value, colour = name)) +
  geom_line()

df = df |> 
  mutate(
    hydro_pumped_storage_actual_aggregated_fr = ifelse(
      is.na(hydro_pumped_storage_actual_aggregated_fr),
      0,
      hydro_pumped_storage_actual_aggregated_fr
    ),
    hydro_pumped_storage_actual_consumption_fr = ifelse(
      is.na(hydro_pumped_storage_actual_consumption_fr),
      0,
      hydro_pumped_storage_actual_consumption_fr
    )
  )
```

Let's visualise the missingness in the rest of the variables:

```{r}
df |> 
  naniar::vis_miss(warn_large_data = F)
```

Remove forecast values as we are using the actuals instead:

Before imputation remove other variables based on following:

There are columns that contains forecast and other that contains the actual value.

We decided to use keep only the actual data for those variables that also have a forecast for, since we can not trace back when the forecast was received by the traders.

```{r}
# Identify columns containing "actual" and "forecast" using grep
actual_columns <- grep("actual", names(df), value = TRUE)
forecast_columns <- grep("forecast", names(df), value = TRUE)
print(actual_columns)
print('')
print(forecast_columns)
```

The solar_forecast_country and the solar_actual_aggregated_country express similar quantities: the former is a forecast of wind and solar power generation as an average of forecasted power output per Market Time Unit and per bidding zone, while the latter expresses the actual aggregated output per Market Time Unit (sum). Since we cannot recover the exact time when the forecasts are published (when the forecasts are available to traders), and we can assume that the forecasts nowadays are accurate, we decided to remove the forecasts. This reasoning is also applied to other variables.

```{r}
remove_forecast <- c('solar_forecast_fr', 'solar_forecast_ch', 'solar_forecast_it','solar_forecast_at', 'wind_offshore_forecast_de', 'wind_onshore_forecast_de', 'wind_onshore_forecast_ch', 'wind_onshore_forecast_at')

df <- df %>% 
  select(!all_of(remove_forecast))
```

```{r}
df |> 
  write_csv("../00 Data Retrieval and Cleaning/0_df_final_not_imputed.csv")
```

### Imputation with Zero and Include Dummies for Missing

```{r}
df = bind_cols(
  df |> select(date),
  df |> 
    select(-date) |> 
    mutate(
      across(everything(), function(x) if_else(is.na(x), 0, x)),
      across(everything(), ~ if_else(is.na(.), 1, 0),
             .names = "{.col}_is_missing")
    )
)
```

```{r}
df |> 
  write_csv("../00 Data Retrieval and Cleaning/0_df_final_imputed.csv")
```

Save the dataset in a file so we can use it in the future with the same imputation.