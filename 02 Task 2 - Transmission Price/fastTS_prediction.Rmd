---
title: "fastTS_prediction"
author: "Federico Deotto"
date: "2024-05-09"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(ggsci)
library(scales)
library(shiny)
library(ncvreg)

library(fastTS)
library(xts)


source('builtin_functions.R')


setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

# Default theme for charts
theme_set(
  theme_bw() +
    theme(  
      plot.title = element_text(face = "bold", size = 14),
      plot.subtitle = element_text(
        face = "italic", size = 10, colour = "green50"
      )
    )
)
```

## Goal

In this Rmarkdown, we analyze the prices using a prediction perspective, i.e., we try to use only the information that is available before the JAO auctions in the morning. Since the time series over the entire time window exhibits clear non-stationarity, we decided to focus on the last period that seems to present 'constant' volatility and is more relevant to our client. We will explore different transformations of the responses and also alter the feature space.


# German Price
```{r}
time_cut <- as.POSIXct("2023-03-01 00:00:00", tz = "UTC")

df <- read_csv("../00 Data Retrieval and Cleaning/0_df_final_imputed_shifting_a_de.csv") %>% 
  filter(date >= time_cut)

#Remove variables with constant variance; they are redundant since we have cut the time window (consider for example year dummies)

variances = df %>%  
  select(-c(date)) %>%  
  mutate_all(as.numeric) %>%
  apply(2, var)

null_variance_cols <- names(variances[variances == 0])

df  %>% 
  nrow() * 0.7

max_lag =24*30 # 1 month - this is the amount of data that we will lose by shifting
```

We can observe that the log transformation is more suitable for the modeling phase. Additionally, we need to shift the data since we have negative prices.
```{r}
df %>% 
  ggplot(aes(date))+
  geom_line(aes(y = day_ahead_price_de))+
  labs(title = 'Price original', x = 'Date', y = 'Price')

df %>% 
  mutate(day_ahead_price_de = log(day_ahead_price_de - min(day_ahead_price_de) +1)) %>% 
  ggplot(aes(date))+
  geom_line(aes(y = day_ahead_price_de))+
  labs(title = 'Price log', x = 'Date', y = 'Price')

df %>% 
  mutate(day_ahead_price_de = tanh(day_ahead_price_de)) %>% 
  ggplot(aes(date))+
  geom_line(aes(y = day_ahead_price_de))+
  labs(title = 'Price tanh', x = 'Date', y = 'Price')
```



```{r}
models1 <- df %>% 
  mutate(day_ahead_price_de = log(day_ahead_price_de - min(day_ahead_price_de) + 1)) %>% 
  model_list(p.train = 0.7, response = 'day_ahead_price_de', nlag = max_lag)

summary(models1)
```

```{r}
r <- model_selected(models1)
```


Looking at those variables that are significantly different from zero we consider now also their squred version.

```{r}
temp <- summary(models1)$table
variables_to_square <- temp %>%
  rownames() %>%
  enframe(name = NULL) %>%
  filter(!str_detect(value, 'lag') & !str_detect(value, 'cal')) %>% 
  pull() %>% 
  sort()
rm(temp)
```

```{r}
models2 <- df %>% 
  mutate(day_ahead_price_de = log(day_ahead_price_de - min(day_ahead_price_de) + 1)) %>%
  mutate(across(variables_to_square, ~ .^2, .names = "{.col}_squared")) %>% 
  model_list(p.train = 0.7, response = 'day_ahead_price_de', nlag = max_lag)

summary(models2)
```

The model that is used as comparison is the one that has best performance in terms of AIC.
```{r}
temp <- summary(models2)$table
variables_after_square <- temp %>%
  rownames() %>%
  enframe(name = NULL) %>%
  filter(!str_detect(value, 'lag') & !str_detect(value, 'cal')) %>% 
  pull() %>% 
  sort()

rm(temp)
```
```{r}
print('Element present in both models')
intersect(variables_to_square, variables_after_square)

print('Element present only in first models, and not relevant anymore')
setdiff(variables_to_square, variables_after_square)

print('Element present only in second models')
setdiff(variables_after_square, variables_to_square)
```

```{r}
s <- model_selected(models2, lag.max = max_lag)
ss <- prediction_step(models1)
```

































